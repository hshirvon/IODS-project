# Regression and model validation

#Heidi Hirvonen 11.11.2020 
#This wee I have been learning simple linear regression

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.

```{r}
date()


lrn14 <- read.table("https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
str(lrn14)
dim(lrn14)
#The data contains 183 variables and 60 observations
attach(lrn14)
#create deep, strategic, surface and attitude

lrn14$d_sm <- D03+D11+D19+D27
lrn14$d_ri <- D07+D14+D22+D30
lrn14$d_ue <- D06+D15+D23+D31

lrn14$deep <- (lrn14$d_sm +lrn14$d_ri +lrn14$d_ue) / 12
lrn14$surf <- (SU02+SU10+SU18+SU26+SU05+SU13+SU21+SU29+SU08+SU16+SU24+SU32)/12
lrn14$stra <- (ST01+ST09+ST17+ST25+ST04+ST12+ST20+ST28)/8

lrn14$Attitude <- (Da+Db+Dc+Dd+De+Df+Dg+Dh+Di+Dj)/10
detach(lrn14)
#Create my own dataset as instructe
heidindata <- data.frame("sukupuoli"=lrn14$gender, lrn14$Age, lrn14$Attitude, lrn14$deep, lrn14$stra, lrn14$surf,  lrn14$Points)
heidindata <- subset(heidindata, lrn14.Points != 0)
setwd("/Users/heidihirvonen/Documents/OPISKELU 2020/MENETELMAOPINNOT/OpenDataScience/IODS-project")
write.csv(heidindata,"data/heidindata.csv" )
newdata <- read.csv("data/heidindata.csv")

heididata <- read.table("data/heidindata.csv", sep=",", header=TRUE)
#Explore the structure and the dimensions of the data 
str(heididata)

#The dataset "newdata" includes 8 variables and 166 observations. It is a subdata of an international survey of Approaches to Learning, which has been collected 3.12.2014 - 10.1.2015. The variables included in the  "newdata" are gender, age, attitude, deep learning, strategic learning, surface learning, points and a running variable X.

plot(heididata)
summary(heididata)
#The age of the respondents is between 17 and 55;  attitude approximately 1,4 - 5,0; deep learning approximately 1.6 - 4,9; strategic learning approximately 1,3 - 5,0; surface learning approximately 1,6 - 4,3 and points 7 - 33. 

# My regression model explains the target (dependent) variable, exam points, with gender, age and attitude. 
my_regression <- lm(lrn14.Points ~ sukupuoli + lrn14.Age + lrn14.Attitude , data = heididata)

#Print out a summary of my regression model
summary(my_regression)

#The regression model explains the target (dependent) variable, exam points, with gender, age and attitude. Attitude has a statistically significant relationship with Points, but gender and age do not. 

#Running the regression again with just attitude as the explanatory variable and print out a summary of the regression model:
my_regression2 <- lm(lrn14.Points ~ lrn14.Attitude , data = heididata)
summary(my_regression2)

#Since gender and age did not have a statistically significant effect, I will analyze the summary of the my_regression2 with attitude as the explanatory variable. 

#The coefficient is 3.25, meaning that when the explanatory variable (attitude) moves one unit, the target variable moves 3.25 units. One unit better attitude, should result in 3.25 more points! 

#The multiple R squared of the model is 0.1906. This means how much of the model is explained by attitude.

#Residuals vs Fitted values
#Normal QQ-plot
#Residuals vs Leverage. 
#Explain the assumptions of the model and interpret the validity of those assumptions based on the diagnostic plots. (0-3 points)

```
